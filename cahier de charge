Cahier des Charges – Projet MirrorMind

1. Contexte
MirrorMind est une application d’intelligence émotionnelle interactive qui aide les utilisateurs à comprendre et gérer leurs émotions à travers l’analyse de la voix, du visage et du texte. Elle agit comme un miroir émotionnel intelligent, combinant IA et psychologie pour favoriser le bien-être mental.
2. Objectifs (MVP)
- Fournir une application web et mobile démontrant :
  - Authentification utilisateur.
  - Tableau de bord avec statistiques de sessions.
  - Module d’exercice : respiration guidée.
  - Module capture : detection basique visage/webcam avec feedback (TFJS / mediapipe).
- Code maintenable, testable et déployable.
-	Chatbot empathique et interactif
-	Journal émotionnel intelligent
-	Recommandations personnalisées et graphiques d’évolution

 3. Périmètre fonctionnel
- Authentification: inscription, connexion, déconnexion.
- Dashboard: visualisation des sessions, graphiques simples.
- Exercices: séquence de respiration guidée avec chrono et instructions.
- Capture: accès caméra, détection simple (présence visage), retour visuel.
- Notifications locales (mobile), gestion du thème (dark/light).

Fonctions hors périmètre MVP:
- Modèles ML complexes, synchronisation offline avancée, paiement.

 4. Contraintes non‑fonctionnelles
- Multi‑plateforme (Web via Vite + React; Mobile via Flutter/Capacitor).
- Respect RGPD (consentement explicite pour audio/vidéo).
- Temps de latence minimal pour feedback caméras.
- Accessibilité et responsive design.
- Couverture de tests unitaires et intégration minimale.

 5. Technologies retenues
- Web: React 18, Vite, Tailwind CSS, Radix UI.
- Mobile: Flutter + Capacitor plugins (camera, notifications).
- ML/vision: TensorFlow.js / MediaPipe.
- Backend: Supabase (auth + stockage).
- Tests: flutter_test (mobile), Jest/React Testing Library (web).
- CI: GitHub Actions.

 6. Architecture de la solution
- Dossier /src → application web.
- Dossier /lib → application Flutter.
- Composants UI partagés, services (api, auth, ml), tests par module.

 7. Critères d'acceptation
- Inscription/connexion fonctionnelles.
- Dashboard accessible et affichant données de sessions fictives.
- Exercice respiration exécutable et traçable.
- Capture webcam détectant visage et affichant retour visuel.
- Tests unitaires critiques verts et build CI qui réussit.

 8. Livrables
- Application web déployable (URL de démo).
- Application mobile compilable (APK/IPA ou snapshot).
- Documentation d'installation et usage.
- Rapport technique + démonstration vidéo (5–10 min).

9. Risques & mesures d'atténuation
- Problèmes d’accès caméra / permissions → tests sur appareils réels.
- Performance ML → démarrer avec modèles légers, profilage.
- Délai d’intégration mobile/web → prioriser features critiques.
